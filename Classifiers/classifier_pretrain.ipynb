{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Transfer learning by training the network on all the train data (i.e. all movements during the 24hr period, rather than\n",
    "only the final movements prior to the target time), and then fine-tuning with the final location data only. This script\n",
    "implements the initial training and saving of a DNN which is later fine tuned ('transfer_learning.ipynb')\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score, f1_score\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_f_score(y_pred,y_true):\n",
    "    print(f\"Accuracy score: {round(accuracy_score(y_true, y_pred) * 100,2)}%\")\n",
    "    print('\\033[92m' + f\"F1 score: {f1_score(y_true, y_pred)}\" + '\\033[0m')\n",
    "    \n",
    "def in_city(x_pred,y_pred):\n",
    "    targets = []\n",
    "    \n",
    "    if (3750901.5068 <= x_pred <= 3770901.5069) and (-19268905.6133 <= y_pred <= -19208905.6133):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def sigmoid(x):\n",
    "    e = np.exp(1)\n",
    "    y = 1/(1+e**(-x))\n",
    "    return y\n",
    "\n",
    "def journey_time(x,y):\n",
    "    \"\"\"\n",
    "    Compute journey time in seconds.\n",
    "    \"\"\"\n",
    "    x = pd.to_datetime(x)\n",
    "    y = pd.to_datetime(y)\n",
    "    return (y-x).total_seconds()\n",
    "\n",
    "def to_binary(x):\n",
    "    result = []\n",
    "    for n in x:\n",
    "        result.append(np.argmax(n))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trajectory_id</th>\n",
       "      <th>time_entry</th>\n",
       "      <th>time_exit</th>\n",
       "      <th>x_entry</th>\n",
       "      <th>y_entry</th>\n",
       "      <th>dist</th>\n",
       "      <th>net_tr</th>\n",
       "      <th>prev_tr</th>\n",
       "      <th>x_home</th>\n",
       "      <th>y_home</th>\n",
       "      <th>nj</th>\n",
       "      <th>dist_pct_ch</th>\n",
       "      <th>j_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>traj_00032f51796fd5437b238e3a9823d13d_31_5</td>\n",
       "      <td>15:03:32</td>\n",
       "      <td>15:10:32</td>\n",
       "      <td>3.773118e+06</td>\n",
       "      <td>-1.914490e+07</td>\n",
       "      <td>94796.788991</td>\n",
       "      <td>46383.455713</td>\n",
       "      <td>31284.419082</td>\n",
       "      <td>3.773413e+06</td>\n",
       "      <td>-1.909828e+07</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-0.248129</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traj_000479418b5561ab694a2870cc04fd43_25_10</td>\n",
       "      <td>15:29:09</td>\n",
       "      <td>15:30:56</td>\n",
       "      <td>3.769978e+06</td>\n",
       "      <td>-1.934136e+07</td>\n",
       "      <td>102860.555932</td>\n",
       "      <td>-8447.209016</td>\n",
       "      <td>-8447.209016</td>\n",
       "      <td>3.771380e+06</td>\n",
       "      <td>-1.933274e+07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.089470</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>traj_000506a39775e5bca661ac80e3f466eb_29_5</td>\n",
       "      <td>15:26:08</td>\n",
       "      <td>15:26:08</td>\n",
       "      <td>3.757468e+06</td>\n",
       "      <td>-1.923860e+07</td>\n",
       "      <td>3447.328292</td>\n",
       "      <td>135037.335584</td>\n",
       "      <td>74302.066130</td>\n",
       "      <td>3.760880e+06</td>\n",
       "      <td>-1.910042e+07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-0.955661</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>traj_0005401ceddaf27a9b7f0d42ef1fbe95_1_4</td>\n",
       "      <td>15:35:18</td>\n",
       "      <td>15:42:05</td>\n",
       "      <td>3.760505e+06</td>\n",
       "      <td>-1.935500e+07</td>\n",
       "      <td>116098.353965</td>\n",
       "      <td>-38952.875270</td>\n",
       "      <td>-39435.784895</td>\n",
       "      <td>3.751328e+06</td>\n",
       "      <td>-1.916236e+07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.514407</td>\n",
       "      <td>407.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>traj_00063a4f6c12e1e4de7d876580620667_3_4</td>\n",
       "      <td>14:54:07</td>\n",
       "      <td>15:05:14</td>\n",
       "      <td>3.766319e+06</td>\n",
       "      <td>-1.917013e+07</td>\n",
       "      <td>68990.640078</td>\n",
       "      <td>-27180.691631</td>\n",
       "      <td>-10903.571713</td>\n",
       "      <td>3.747364e+06</td>\n",
       "      <td>-1.927846e+07</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.187711</td>\n",
       "      <td>667.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 trajectory_id time_entry time_exit  \\\n",
       "0   traj_00032f51796fd5437b238e3a9823d13d_31_5   15:03:32  15:10:32   \n",
       "1  traj_000479418b5561ab694a2870cc04fd43_25_10   15:29:09  15:30:56   \n",
       "2   traj_000506a39775e5bca661ac80e3f466eb_29_5   15:26:08  15:26:08   \n",
       "3    traj_0005401ceddaf27a9b7f0d42ef1fbe95_1_4   15:35:18  15:42:05   \n",
       "4    traj_00063a4f6c12e1e4de7d876580620667_3_4   14:54:07  15:05:14   \n",
       "\n",
       "        x_entry       y_entry           dist         net_tr       prev_tr  \\\n",
       "0  3.773118e+06 -1.914490e+07   94796.788991   46383.455713  31284.419082   \n",
       "1  3.769978e+06 -1.934136e+07  102860.555932   -8447.209016  -8447.209016   \n",
       "2  3.757468e+06 -1.923860e+07    3447.328292  135037.335584  74302.066130   \n",
       "3  3.760505e+06 -1.935500e+07  116098.353965  -38952.875270 -39435.784895   \n",
       "4  3.766319e+06 -1.917013e+07   68990.640078  -27180.691631 -10903.571713   \n",
       "\n",
       "         x_home        y_home   nj  dist_pct_ch  j_time  \n",
       "0  3.773413e+06 -1.909828e+07  5.0    -0.248129   420.0  \n",
       "1  3.771380e+06 -1.933274e+07  3.0     0.089470   107.0  \n",
       "2  3.760880e+06 -1.910042e+07  3.0    -0.955661     0.0  \n",
       "3  3.751328e+06 -1.916236e+07  3.0     0.514407   407.0  \n",
       "4  3.747364e+06 -1.927846e+07  4.0     0.187711   667.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data_train/all_features.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dpc</th>\n",
       "      <th>home</th>\n",
       "      <th>start_CC</th>\n",
       "      <th>net_tr_b</th>\n",
       "      <th>prev_tr_b</th>\n",
       "      <th>odd_even_nj</th>\n",
       "      <th>dist_scaled</th>\n",
       "      <th>jt_scaled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trajectory_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traj_0000a8602cf2def930488dee7cdad104_1_0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739870</td>\n",
       "      <td>0.009806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traj_0000a8602cf2def930488dee7cdad104_1_1</th>\n",
       "      <td>0.398189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434215</td>\n",
       "      <td>0.012532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traj_0000a8602cf2def930488dee7cdad104_1_2</th>\n",
       "      <td>0.417767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.290016</td>\n",
       "      <td>0.024128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traj_0000a8602cf2def930488dee7cdad104_1_3</th>\n",
       "      <td>0.494620</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.283770</td>\n",
       "      <td>0.047728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traj_0000a8602cf2def930488dee7cdad104_1_4</th>\n",
       "      <td>0.471354</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251197</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                dpc  home  start_CC  net_tr_b  \\\n",
       "trajectory_id                                                                   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_0  0.500000     0         0         1   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_1  0.398189     0         0         1   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_2  0.417767     0         0         1   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_3  0.494620     0         0         1   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_4  0.471354     0         0         1   \n",
       "\n",
       "                                           prev_tr_b  odd_even_nj  \\\n",
       "trajectory_id                                                       \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_0          0            1   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_1          1            1   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_2          1            1   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_3          1            1   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_4          1            1   \n",
       "\n",
       "                                           dist_scaled  jt_scaled  \n",
       "trajectory_id                                                      \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_0     0.739870   0.009806  \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_1     0.434215   0.012532  \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_2     0.290016   0.024128  \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_3     0.283770   0.047728  \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_4     0.251197   0.000000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data_train/all_binary_features.csv')\n",
    "df.set_index(\"trajectory_id\", inplace=True)\n",
    "y = df[\"final_loc\"].values\n",
    "df.drop([\"dist\",\"dist_pct_ch\",\"j_time\",\"final_loc\"], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_entry</th>\n",
       "      <th>y_entry</th>\n",
       "      <th>dist</th>\n",
       "      <th>net_tr</th>\n",
       "      <th>prev_tr</th>\n",
       "      <th>x_home</th>\n",
       "      <th>y_home</th>\n",
       "      <th>nj</th>\n",
       "      <th>j_time</th>\n",
       "      <th>dpc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trajectory_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>traj_0000a8602cf2def930488dee7cdad104_1_0</th>\n",
       "      <td>6.574149</td>\n",
       "      <td>7.280896</td>\n",
       "      <td>5.162152</td>\n",
       "      <td>4.997665</td>\n",
       "      <td>3.54961</td>\n",
       "      <td>6.574149</td>\n",
       "      <td>7.280896</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>2.382017</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traj_0000a8602cf2def930488dee7cdad104_1_1</th>\n",
       "      <td>6.573329</td>\n",
       "      <td>7.286063</td>\n",
       "      <td>4.930779</td>\n",
       "      <td>4.997665</td>\n",
       "      <td>3.54961</td>\n",
       "      <td>6.574149</td>\n",
       "      <td>7.280896</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>2.488551</td>\n",
       "      <td>-0.399910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traj_0000a8602cf2def930488dee7cdad104_1_2</th>\n",
       "      <td>6.573436</td>\n",
       "      <td>7.285412</td>\n",
       "      <td>4.755589</td>\n",
       "      <td>4.997665</td>\n",
       "      <td>3.54961</td>\n",
       "      <td>6.574149</td>\n",
       "      <td>7.280896</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>2.773055</td>\n",
       "      <td>-0.379066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traj_0000a8602cf2def930488dee7cdad104_1_3</th>\n",
       "      <td>6.573438</td>\n",
       "      <td>7.285384</td>\n",
       "      <td>4.746139</td>\n",
       "      <td>4.997665</td>\n",
       "      <td>3.54961</td>\n",
       "      <td>6.574149</td>\n",
       "      <td>7.280896</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>3.069298</td>\n",
       "      <td>-0.305729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>traj_0000a8602cf2def930488dee7cdad104_1_4</th>\n",
       "      <td>6.573441</td>\n",
       "      <td>7.285233</td>\n",
       "      <td>4.693225</td>\n",
       "      <td>4.997665</td>\n",
       "      <td>3.54961</td>\n",
       "      <td>6.574149</td>\n",
       "      <td>7.280896</td>\n",
       "      <td>0.778151</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.326653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            x_entry   y_entry      dist  \\\n",
       "trajectory_id                                                             \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_0  6.574149  7.280896  5.162152   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_1  6.573329  7.286063  4.930779   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_2  6.573436  7.285412  4.755589   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_3  6.573438  7.285384  4.746139   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_4  6.573441  7.285233  4.693225   \n",
       "\n",
       "                                             net_tr  prev_tr    x_home  \\\n",
       "trajectory_id                                                            \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_0  4.997665  3.54961  6.574149   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_1  4.997665  3.54961  6.574149   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_2  4.997665  3.54961  6.574149   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_3  4.997665  3.54961  6.574149   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_4  4.997665  3.54961  6.574149   \n",
       "\n",
       "                                             y_home        nj    j_time  \\\n",
       "trajectory_id                                                             \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_0  7.280896  0.778151  2.382017   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_1  7.280896  0.778151  2.488551   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_2  7.280896  0.778151  2.773055   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_3  7.280896  0.778151  3.069298   \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_4  7.280896  0.778151  0.000000   \n",
       "\n",
       "                                                dpc  \n",
       "trajectory_id                                        \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_0  0.000000  \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_1 -0.399910  \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_2 -0.379066  \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_3 -0.305729  \n",
       "traj_0000a8602cf2def930488dee7cdad104_1_4 -0.326653  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.apply(abs,axis=1)\n",
    "df = df.apply(np.log10,axis=1)\n",
    "df[df == -np.inf] = 0.0\n",
    "df.fillna(0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "X = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Random over-sampling for pre-training the network\n",
    "\"\"\"\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 571050), (1, 571050)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "import math\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = .005\n",
    "    drop = 0.25\n",
    "    epochs_drop = 2\n",
    "    lrate = initial_lrate * math.pow(drop,  \n",
    "           math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "        self.lr = []\n",
    " \n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.lr.append(step_decay(len(self.losses)))\n",
    "\n",
    "loss_history = LossHistory()\n",
    "lrate = LearningRateScheduler(step_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3135: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 256)               2304      \n",
      "_________________________________________________________________\n",
      "activation_1 (LeakyReLU)     (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "BN1 (BatchNormalization)     (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "DO1 (Dropout)                (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 1024)              263168    \n",
      "_________________________________________________________________\n",
      "activation_2 (LeakyReLU)     (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "BN2 (BatchNormalization)     (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "DO2 (Dropout)                (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "activation_3 (LeakyReLU)     (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "BN3 (BatchNormalization)     (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "DO3 (Dropout)                (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "fc3 (Dense)                  (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "activation_4 (LeakyReLU)     (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "BN4 (BatchNormalization)     (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "classifier (Dense)           (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 2,380,034\n",
      "Trainable params: 2,373,378\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',input_dim = X.shape[1], activation=None, name='layer1'))\n",
    "NN_model.add(keras.layers.LeakyReLU(alpha=0.3, name='activation_1'))\n",
    "NN_model.add(BatchNormalization(name='BN1'))\n",
    "NN_model.add(Dropout(0.1, name='DO1'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(1024, kernel_initializer='normal',activation=None, kernel_regularizer=keras.regularizers.l1(0.000),\n",
    "                   name='fc1'))\n",
    "NN_model.add(keras.layers.LeakyReLU(alpha=0.3, name='activation_2'))\n",
    "NN_model.add(BatchNormalization(name='BN2'))\n",
    "NN_model.add(Dropout(0.1, name='DO2'))\n",
    "\n",
    "\n",
    "NN_model.add(Dense(1024, kernel_initializer='normal',activation=None, kernel_regularizer=keras.regularizers.l1(0.000),\n",
    "                   name='fc2'))\n",
    "NN_model.add(keras.layers.LeakyReLU(alpha=0.3, name='activation_3'))\n",
    "NN_model.add(BatchNormalization(name='BN3'))\n",
    "NN_model.add(Dropout(0.1, name='DO3'))\n",
    "\n",
    "NN_model.add(Dense(1024, kernel_initializer='normal',activation=None, kernel_regularizer=keras.regularizers.l1(0.000),\n",
    "                   name='fc3'))\n",
    "NN_model.add(keras.layers.LeakyReLU(alpha=0.3, name='activation_4'))\n",
    "NN_model.add(BatchNormalization(name='BN4'))\n",
    "\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(2, activation='softmax', name='classifier'))\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=.0, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 651409 samples, validate on 162853 samples\n",
      "Epoch 1/50\n",
      "651409/651409 [==============================] - 301s 462us/step - loss: 0.1079 - acc: 0.9324 - val_loss: 0.0962 - val_acc: 0.9372\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09620, saving model to Weights-001--0.09620.hdf5\n",
      "Epoch 2/50\n",
      "651409/651409 [==============================] - 296s 454us/step - loss: 0.0923 - acc: 0.9350 - val_loss: 0.0908 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09620 to 0.09084, saving model to Weights-002--0.09084.hdf5\n",
      "Epoch 3/50\n",
      "651409/651409 [==============================] - 290s 445us/step - loss: 0.0923 - acc: 0.9347 - val_loss: 0.0890 - val_acc: 0.9369\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09084 to 0.08904, saving model to Weights-003--0.08904.hdf5\n",
      "Epoch 4/50\n",
      "651409/651409 [==============================] - 287s 440us/step - loss: 0.0906 - acc: 0.9356 - val_loss: 0.0879 - val_acc: 0.9379\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08904 to 0.08788, saving model to Weights-004--0.08788.hdf5\n",
      "Epoch 5/50\n",
      "651409/651409 [==============================] - 291s 447us/step - loss: 0.0903 - acc: 0.9355 - val_loss: 0.0874 - val_acc: 0.9380\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.08788 to 0.08743, saving model to Weights-005--0.08743.hdf5\n",
      "Epoch 6/50\n",
      "651409/651409 [==============================] - 296s 454us/step - loss: 0.0896 - acc: 0.9356 - val_loss: 0.0867 - val_acc: 0.9374\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.08743 to 0.08669, saving model to Weights-006--0.08669.hdf5\n",
      "Epoch 7/50\n",
      "651409/651409 [==============================] - 289s 444us/step - loss: 0.0894 - acc: 0.9356 - val_loss: 0.0866 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.08669 to 0.08657, saving model to Weights-007--0.08657.hdf5\n",
      "Epoch 8/50\n",
      "651409/651409 [==============================] - 289s 444us/step - loss: 0.0892 - acc: 0.9358 - val_loss: 0.0865 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.08657 to 0.08646, saving model to Weights-008--0.08646.hdf5\n",
      "Epoch 9/50\n",
      "651409/651409 [==============================] - 289s 443us/step - loss: 0.0892 - acc: 0.9357 - val_loss: 0.0865 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 10/50\n",
      "651409/651409 [==============================] - 290s 445us/step - loss: 0.0891 - acc: 0.9359 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.08646 to 0.08645, saving model to Weights-010--0.08645.hdf5\n",
      "Epoch 11/50\n",
      "651409/651409 [==============================] - 294s 452us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.08645 to 0.08643, saving model to Weights-011--0.08643.hdf5\n",
      "Epoch 12/50\n",
      "651409/651409 [==============================] - 294s 452us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/50\n",
      "651409/651409 [==============================] - 295s 453us/step - loss: 0.0890 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.08643 to 0.08643, saving model to Weights-013--0.08643.hdf5\n",
      "Epoch 14/50\n",
      "651409/651409 [==============================] - 288s 442us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00014: val_loss did not improve\n",
      "Epoch 15/50\n",
      "651409/651409 [==============================] - 283s 434us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/50\n",
      "651409/651409 [==============================] - 281s 432us/step - loss: 0.0892 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00016: val_loss did not improve\n",
      "Epoch 17/50\n",
      "651409/651409 [==============================] - 299s 459us/step - loss: 0.0891 - acc: 0.9359 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/50\n",
      "651409/651409 [==============================] - 288s 442us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/50\n",
      "651409/651409 [==============================] - 284s 437us/step - loss: 0.0890 - acc: 0.9359 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00019: val_loss did not improve\n",
      "Epoch 20/50\n",
      "651409/651409 [==============================] - 279s 428us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 21/50\n",
      "651409/651409 [==============================] - 277s 425us/step - loss: 0.0891 - acc: 0.9359 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00021: val_loss did not improve\n",
      "Epoch 22/50\n",
      "651409/651409 [==============================] - 278s 427us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/50\n",
      "651409/651409 [==============================] - 278s 427us/step - loss: 0.0891 - acc: 0.9359 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/50\n",
      "651409/651409 [==============================] - 277s 426us/step - loss: 0.0891 - acc: 0.9359 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/50\n",
      "651409/651409 [==============================] - 277s 425us/step - loss: 0.0891 - acc: 0.9359 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 26/50\n",
      "651409/651409 [==============================] - 279s 428us/step - loss: 0.0890 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/50\n",
      "651409/651409 [==============================] - 278s 427us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/50\n",
      "651409/651409 [==============================] - 276s 424us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 29/50\n",
      "651409/651409 [==============================] - 278s 427us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/50\n",
      "651409/651409 [==============================] - 304s 467us/step - loss: 0.0891 - acc: 0.9356 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/50\n",
      "651409/651409 [==============================] - 296s 454us/step - loss: 0.0890 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00031: val_loss did not improve\n",
      "Epoch 32/50\n",
      "651409/651409 [==============================] - 296s 454us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/50\n",
      "651409/651409 [==============================] - 295s 452us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/50\n",
      "651409/651409 [==============================] - 295s 453us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/50\n",
      "651409/651409 [==============================] - 294s 452us/step - loss: 0.0891 - acc: 0.9359 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/50\n",
      "651409/651409 [==============================] - 299s 458us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.08643 to 0.08642, saving model to Weights-036--0.08642.hdf5\n",
      "Epoch 37/50\n",
      "651409/651409 [==============================] - 295s 453us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/50\n",
      "651409/651409 [==============================] - 297s 455us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/50\n",
      "651409/651409 [==============================] - 295s 452us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/50\n",
      "651409/651409 [==============================] - 289s 444us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9377\n",
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/50\n",
      "651409/651409 [==============================] - 287s 441us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/50\n",
      "651409/651409 [==============================] - 293s 451us/step - loss: 0.0891 - acc: 0.9357 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 43/50\n",
      "651409/651409 [==============================] - 289s 444us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/50\n",
      "651409/651409 [==============================] - 293s 450us/step - loss: 0.0892 - acc: 0.9355 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/50\n",
      "651409/651409 [==============================] - 290s 446us/step - loss: 0.0891 - acc: 0.9360 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/50\n",
      "651409/651409 [==============================] - 289s 444us/step - loss: 0.0891 - acc: 0.9359 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/50\n",
      "651409/651409 [==============================] - 299s 459us/step - loss: 0.0892 - acc: 0.9356 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/50\n",
      "651409/651409 [==============================] - 290s 445us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/50\n",
      "651409/651409 [==============================] - 294s 451us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/50\n",
      "651409/651409 [==============================] - 302s 463us/step - loss: 0.0891 - acc: 0.9358 - val_loss: 0.0864 - val_acc: 0.9376\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d210b0e668>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_binary = to_categorical(y)\n",
    "\n",
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint,loss_history,lrate]\n",
    "class_weight = {0: .5,\n",
    "                1: .66}\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y_binary,test_size=0,random_state=410,shuffle=True)\n",
    "\n",
    "NN_model.fit(x_train, y_train, epochs=50, batch_size=256, validation_split = 0.2,\n",
    "             callbacks=callbacks_list, class_weight=class_weight) # -- not used because of oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Select the opimal weights and save the model for further transfer learning\n",
    "\"\"\"\n",
    "\n",
    "weights_file = 'Weights-036--0.08642.hdf5' # choose the best checkpoint\n",
    "NN_model.load_weights(weights_file) # load it\n",
    "NN_model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "NN_model.save('pretrained_model_wed.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
